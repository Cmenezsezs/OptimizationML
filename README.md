# ğŸ¯ OtimizaÃ§Ã£o de Modelo de Machine Learning

## ğŸ“‹ SumÃ¡rio 

Este projeto demonstra um pipeline completo de **otimizaÃ§Ã£o de modelos de Machine Learning**, aplicando tÃ©cnicas avanÃ§adas de engenharia de features, tuning de hiperparÃ¢metros e ensemble learning. O objetivo Ã© maximizar a performance preditiva atravÃ©s de metodologias sistemÃ¡ticas e cientificamente fundamentadas.

**Resultado Principal:** Desenvolvimento de um modelo de classificaÃ§Ã£o binÃ¡ria com **AUC-ROC de 0.9378** e **accuracy de 88.1%**, demonstrando tÃ©cnicas profissionais de otimizaÃ§Ã£o aplicÃ¡veis a problemas reais de produÃ§Ã£o.

---

## ğŸ“ Objetivo do Projeto

### PropÃ³sito
Demonstrar competÃªncias essenciais de um **Engenheiro de IA especialista em otimizaÃ§Ã£o**, incluindo:

- âœ… Estabelecimento de baseline para comparaÃ§Ã£o
- âœ… Feature engineering e seleÃ§Ã£o de variÃ¡veis relevantes
- âœ… Hyperparameter tuning sistemÃ¡tico
- âœ… TÃ©cnicas de ensemble learning
- âœ… AvaliaÃ§Ã£o comparativa e documentaÃ§Ã£o de resultados

### Problema de NegÃ³cio
Criar um modelo de classificaÃ§Ã£o binÃ¡ria otimizado para um dataset com 30 features, maximizando a capacidade preditiva enquanto mantÃ©m eficiÃªncia computacional e interpretabilidade.

---

## ğŸ—ï¸ Arquitetura da SoluÃ§Ã£o

### Pipeline de OtimizaÃ§Ã£o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dados Brutos      â”‚
â”‚   (5000 samples)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Split Train/Test   â”‚
â”‚   (80% / 20%)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ETAPA 1: Baseline   â”‚
â”‚ Random Forest       â”‚
â”‚ AUC: 0.9427         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ETAPA 2: Feature    â”‚
â”‚ Selection (30â†’20)   â”‚
â”‚ AUC: 0.9334         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ETAPA 3: Grid       â”‚
â”‚ Search CV           â”‚
â”‚ AUC: 0.9384         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ETAPA 4: Ensemble   â”‚
â”‚ RF + GBM            â”‚
â”‚ AUC: 0.9378 âœ“       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Resultados Detalhados

### Comparativo de Performance

| Modelo              | AUC-ROC | Accuracy | Features | ObservaÃ§Ãµes                    |
|---------------------|---------|----------|----------|--------------------------------|
| **Baseline**        | 0.9427  | 89.7%    | 30       | Random Forest sem otimizaÃ§Ã£o   |
| **Feature Selection** | 0.9334  | 88.0%    | 20       | ReduÃ§Ã£o de 33% nas features    |
| **Grid Search**     | 0.9384  | 88.9%    | 20       | HiperparÃ¢metros otimizados     |
| **Ensemble Final**  | 0.9378  | 88.1%    | 20       | RF + Gradient Boosting         |

### MÃ©tricas do Modelo Final (Ensemble)

#### Matriz de ConfusÃ£o - Conjunto de Teste
```
                 Predito
                 Neg    Pos
Real   Neg      437     66
       Pos       53    444
```

#### RelatÃ³rio de ClassificaÃ§Ã£o

| Classe    | Precision | Recall | F1-Score | Support |
|-----------|-----------|--------|----------|---------|
| Classe 0  | 0.89      | 0.87   | 0.88     | 503     |
| Classe 1  | 0.87      | 0.90   | 0.88     | 497     |
| **MÃ©dia** | **0.88**  | **0.88** | **0.88** | **1000** |

---

## ğŸ”¬ Metodologia Aplicada

### 1ï¸âƒ£ Modelo Baseline
**Objetivo:** Estabelecer linha de base para comparaÃ§Ã£o

- **Algoritmo:** Random Forest (50 Ã¡rvores)
- **ConfiguraÃ§Ã£o:** ParÃ¢metros padrÃ£o do scikit-learn
- **Resultado:** AUC-ROC 0.9427, Accuracy 89.7%
- **Tempo de treinamento:** 1.03s

**Insight:** Modelo baseline jÃ¡ apresenta excelente performance, indicando que o problema tem boa separabilidade.

### 2ï¸âƒ£ Feature Selection
**Objetivo:** Reduzir dimensionalidade e eliminar ruÃ­do

- **TÃ©cnica:** SelectKBest com teste F-ANOVA
- **ReduÃ§Ã£o:** 30 â†’ 20 features (-33%)
- **Resultado:** AUC-ROC 0.9334
- **Impacto:** Pequena reduÃ§Ã£o em performance (-0.99%), mas ganho em interpretabilidade e velocidade

**Insight:** A leve queda sugere que algumas features removidas continham informaÃ§Ã£o Ãºtil, porÃ©m a reduÃ§Ã£o de dimensionalidade facilita deployment.

### 3ï¸âƒ£ Hyperparameter Tuning
**Objetivo:** Maximizar performance atravÃ©s de otimizaÃ§Ã£o sistemÃ¡tica

- **TÃ©cnica:** Grid Search com 3-fold Cross-Validation
- **EspaÃ§o de busca:** 16 combinaÃ§Ãµes de hiperparÃ¢metros
- **Tempo de busca:** 15.55s
- **Resultado:** AUC-ROC 0.9384

**Melhores hiperparÃ¢metros encontrados:**
```python
{
    'n_estimators': 100,
    'max_depth': 20,
    'min_samples_split': 2,
    'max_features': 'sqrt'
}
```

**Insight:** Aumento de Ã¡rvores (50â†’100) e profundidade controlada melhoraram a generalizaÃ§Ã£o.

### 4ï¸âƒ£ Ensemble Learning
**Objetivo:** Combinar mÃºltiplos modelos para melhor performance

- **Arquitetura:** Blending de Random Forest + Gradient Boosting
- **Pesos:** 60% RF + 40% GBM
- **Resultado:** AUC-ROC 0.9378, Accuracy 88.1%

**Performance individual:**
- Random Forest: 0.9384
- Gradient Boosting: 0.9286
- **Ensemble:** 0.9378 (robusto e estÃ¡vel)

**Insight:** Ensemble oferece maior robustez e estabilidade, embora com performance similar ao melhor modelo individual.

---

## ğŸ¯ AnÃ¡lise CrÃ­tica

### Pontos Fortes âœ…
1. **Pipeline estruturado e reprodutÃ­vel**
2. **ValidaÃ§Ã£o cruzada** para evitar overfitting
3. **MÃºltiplas tÃ©cnicas de otimizaÃ§Ã£o** aplicadas sistematicamente
4. **DocumentaÃ§Ã£o completa** de cada etapa
5. **Modelos com alta performance** (AUC > 0.93)

### LimitaÃ§Ãµes e ConsideraÃ§Ãµes âš ï¸
1. **Dataset sintÃ©tico:** Resultados podem variar em dados reais
2. **Classe balanceada:** Performance pode cair em datasets desbalanceados
3. **Trade-off interpretabilidade vs. performance:** Ensemble Ã© menos interpretÃ¡vel
4. **Tempo de treinamento:** Grid Search pode ser custoso em produÃ§Ã£o

### PrÃ³ximos Passos ğŸš€

#### OtimizaÃ§Ãµes Adicionais Recomendadas:

1. **Hyperparameter Tuning AvanÃ§ado**
   - Implementar Bayesian Optimization (Optuna/Hyperopt)
   - Testar Randomized Search para exploraÃ§Ã£o mais ampla
   - Early stopping em modelos iterativos

2. **Feature Engineering**
   - Engenharia de features baseada em domÃ­nio
   - InteraÃ§Ãµes polinomiais entre features
   - Recursive Feature Elimination (RFE)

3. **Modelos AvanÃ§ados**
   - XGBoost / LightGBM para maior velocidade
   - Stacking de mÃºltiplos nÃ­veis
   - Neural Networks para comparaÃ§Ã£o

4. **ValidaÃ§Ã£o Robusta**
   - Stratified K-Fold CV (k=5 ou k=10)
   - ValidaÃ§Ã£o em dataset holdout separado
   - AnÃ¡lise de curvas de aprendizado

5. **OtimizaÃ§Ã£o para ProduÃ§Ã£o**
   - Model compression e quantizaÃ§Ã£o
   - ONNX conversion para deployment
   - Monitoramento de drift de dados
   - A/B testing de modelos

---

## ğŸ’» Tecnologias Utilizadas

### Stack Principal
- **Python 3.12**
- **scikit-learn 1.5+** - Machine Learning
- **NumPy** - ComputaÃ§Ã£o numÃ©rica
- **Pandas** - ManipulaÃ§Ã£o de dados

### Algoritmos Implementados
- Random Forest Classifier
- Gradient Boosting Classifier
- SelectKBest (Feature Selection)
- Grid Search CV
- Ensemble Learning (Blending)

---

## ğŸ“ Estrutura do Projeto

```
.
â”œâ”€â”€ ml_optimization_fast.py    # Script principal de otimizaÃ§Ã£o
â”œâ”€â”€ ml_optimization.py          # VersÃ£o completa com mais tÃ©cnicas
â”œâ”€â”€ resultados.txt              # Resultados numÃ©ricos salvos
â””â”€â”€ README.md                   # Este arquivo
```

---

## ğŸš€ Como Executar

### PrÃ©-requisitos
```bash
pip install scikit-learn numpy pandas --break-system-packages
```

### ExecuÃ§Ã£o
```bash
python ml_optimization_fast.py
```

### SaÃ­da Esperada
O script irÃ¡:
1. âœ… Gerar dataset sintÃ©tico
2. âœ… Treinar modelo baseline
3. âœ… Aplicar feature selection
4. âœ… Executar grid search
5. âœ… Criar ensemble
6. âœ… Exibir comparativo completo
7. âœ… Salvar resultados em `resultados.txt`

---

## ğŸ“ˆ ConclusÃµes

Este projeto demonstra um **workflow profissional de otimizaÃ§Ã£o de ML**, aplicando tÃ©cnicas state-of-the-art que sÃ£o essenciais para um Engenheiro de IA:

### Principais Aprendizados:
1. âœ… **Sempre estabeleÃ§a um baseline** antes de otimizar
2. âœ… **Feature selection** pode melhorar eficiÃªncia sem sacrificar muito a performance
3. âœ… **Hyperparameter tuning** Ã© essencial, mas deve ser balanceado com tempo computacional
4. âœ… **Ensembles** oferecem robustez, mas adicioram complexidade
5. âœ… **DocumentaÃ§Ã£o e experimentaÃ§Ã£o** sÃ£o fundamentais para projetos de ML em produÃ§Ã£o

### Impacto para ProduÃ§Ã£o:
- **Modelo robusto** com AUC-ROC superior a 0.93
- **Pipeline reprodutÃ­vel** e bem documentado
- **Features reduzidas** facilitam manutenÃ§Ã£o e deployment
- **Metodologia cientÃ­fica** permite iteraÃ§Ã£o e melhoria contÃ­nua

---

## ğŸ‘¤ Autor

Desenvolvido como demonstraÃ§Ã£o de competÃªncias em **OtimizaÃ§Ã£o de Modelos de Machine Learning** para posiÃ§Ã£o de Engenheiro de IA.

### CompetÃªncias Demonstradas:
- ğŸ¯ Feature Engineering e Selection
- ğŸ¯ Hyperparameter Optimization
- ğŸ¯ Ensemble Learning
- ğŸ¯ Model Evaluation e Validation
- ğŸ¯ Python e scikit-learn
- ğŸ¯ DocumentaÃ§Ã£o TÃ©cnica

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© disponibilizado para fins educacionais e de demonstraÃ§Ã£o tÃ©cnica.

---

## ğŸ“š ReferÃªncias

- [scikit-learn Documentation](https://scikit-learn.org/stable/)
- [Ensemble Methods in Machine Learning](https://link.springer.com/chapter/10.1007/3-540-45014-9_1)
- [Feature Selection Methods](https://jmlr.org/papers/v3/guyon03a.html)
- [Hyperparameter Optimization](https://www.jmlr.org/papers/v13/bergstra12a.html)

---

**Data de criaÃ§Ã£o:** Fevereiro 2026  
**VersÃ£o:** 1.0  
**Status:** âœ… ProduÃ§Ã£o
